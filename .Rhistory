testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats()
?bats
??bats
install.packages("BAT")
?bats
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
modeflfit=bats(testing)
library(BATS)
library(BAT)
modeflfit=bats(testing)
install.packages("forecast")
modeflfit=bats(testing)
library(forecast)
modeflfit=bats(testing)
modeflfit= bats(tstrain)
pred=predict(modelfit,tstest)
tstest = ts(training$visitsTumblr)
pred=predict(modelfit,tstest)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfit= bats(tstrain)
pred=predict(modelfit,tstest)
pred=forecast(modelfit,tstest)
?forecast
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
pred=forecast(modeflfittest)
accuracy(pred,tstest)
pred1
fcast=forecast(modeflfittest)
accuracy(fcast,tstest)
confusionMatrix(fcast,tstest)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
fcast=forecast(modeflfittest)
confusionMatrix(fcast,tstest)
?confusionMatrix
?accuracy
accuracy(fcast,tstest)
tstest
fcast
accuracy(fcast,tstest)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelfit1=train(diagnosis~.,method="rf",data=training)
modelfit2=train(diagnosis~.,method="gbm",data=training,verbose=FALSE)
modelfit3=train(diagnosis~.,method="lda",data=training)
pred1=predict(modelfit1,testing[,-1])
pred2=predict(modelfit2,testing[,-1])
pred3=predict(modelfit3,testing[,-1])
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
combmodfit=train(diagnosis~.,method="rf",data=predDF)
combpred=predict(combmodfit,predDF)
confusionMatrix(combpred,testing$diagnosis)
confusionMatrix(pred1,testing$diagnosis)
confusionMatrix(pred2,testing$diagnosis)
confusionMatrix(pred3,testing$diagnosis)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest = ts(training$visitsTumblr)
library(forecast)
modeflfittrain= bats(tstrain)
modeflfittest= bats(tstest)
fcast=forecast(modeflfittest)
length(tstrain)
length(tstest)
class(fcast)
dim(fcast)
fcast
fcast=forecast(modeflfittrain)
fcast
fcast$fitted
confusionMatrix(fcast$fitted,tstest)
tstest
modeflfittest= bats(tstest)
?forecats
?forecast
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
set.seed(3523)
library(AppliedPredictiveModeling)
library(enet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
?enet
??enet
library(elasticnet)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
plot.enet(modelfit)
?plot.enet
?plot.enet
library(AppliedPredictiveModeling)
library(elasticnet)
library(enet)
library(caret)
?plot.enet
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
summary(modelfit)
modelfit
enet
?enet
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
#modelfit=train(CompressiveStrength~.,method="lasso",data=training)
modelfit=enet(as.matrix(training[,-9]),as.matrix(training[,9]),lambda=0)
png("plot1.png",width = 480, height = 480, units = "px")
plot(modelfit)
dev.off()
names(training)
install.packages("LATEX")
library(UsingR)
mod=lm(parent~child,data="Galton")
mod=lm(parent~child,data=Galton)
summary(mod)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
p=qplot(parent,child,data=Galton,geom=c("point", "smooth"),abline=lm(parent~child,data=Galton))
print(p)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
p=qplot(parent,child,data=Galton,geom=c("point", "smooth"))
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
p=plot(parent,child,data=Galton,geom=c("point", "smooth"))
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
library(ggplot2)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
p=plot(parent,child,data=Galton,geom=c("point", "smooth"))
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
p=plot(parent,child,data=Galton)
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
data(Galton)
p=plot(parent,child,data=Galton)
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
data(Galton)
head(Galton)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
data(Galton)
p=plot(Galton$parent,Galton$child,xlab="Parent's height",ylab="Child's Height",bg="lightblue",col="Black",pch=21)
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
options(warn=-1)
suppressPackageStartupMessages(library(ggplot2));suppressPackageStartupMessages(library(UsingR))
data(Galton)
p=plot(Galton$parent,Galton$child,xlab="Parent's height",ylab="Child's Height",bg="lightblue",col="Black",pch=10)
p=p+abline(lm(parent~child,data=Galton),lwd=2)
print(p)
?qplot
?ggplot
p=qplot(parent,child,data=Galton)
print(p)
p=p+abline(lm(parent~child,data=Galton),lwd=2,col="red")
print(p)
p=p+abline(lm(parent~child,data=Galton),lwd=2)
dev.off()
p=qplot(parent,child,data=Galton)
p=p+abline(lm(parent~child,data=Galton),lwd=2,col="red")
print(p)
p=qplot(parent,child,data=Galton,geom=c("smooth"))
dev.off()
p=qplot(parent,child,data=Galton,geom=c("smooth"))
print(p)
dev.off()
p=plot(Galton$parent,Galton$child,xlab="Parent's height",ylab="Child's Height",bg="lightblue",col="Black",cex=1.1,pch=21,frame=FALSE)
p=p+abline(lm(parent~child,data=Galton),lwd=2,col="red")
suppressFunctionOutput()
?suppress
install.packages("tm")
corpus<-Corpus(DirSource("/Users/malaydas/Documents/Data Science/Capstone Project/final/en_US"), readerControl = list(reader=readPlain))
library(tm)
library(stringi)
corpus<-Corpus(DirSource("/Users/malaydas/Documents/Data Science/Capstone Project/final/en_US"), readerControl = list(reader=readPlain))
summary(corpus)
corpus[[1][1]]
corpus[1][1]
corpus[1]
corpus[[1]]
corpus[[1][1]]
corpus[[1]][1]
corpus[[1]][1][1]
corpus[[2]][1]
corpus[[2]][1:3]
corpus[[2]]
corpus[[2]][[1][1]]
corpus[[2]][[1]
]
```{r,echo=FALSE,results='hide'}
## Removing Punctuation
doc <- tm_map(doc,removePunctuation)
gc()
## Removing White Space
doc <- tm_map(doc,stripWhitespace)
gc()
## Removing stopwords
doc <- tm_map(doc, removeWords, stopwords("english"))
gc()
## Removing common word endings (e.g., “ing”, “es”, “s”)
doc <- tm_map(doc, stemDocument)
gc()
## Removing Numbers
doc <- tm_map(doc,removeNumbers)
gc()
```
load("/Users/malaydas/Downloads/transitionMatrix.RData")
View(transitionMatrix)
install.packages("markovchain")
?markovchain
library(markovchain)
?markovchain
library(markovchain)
?markovchain
load("/Users/malaydas/Downloads/transitionMatrix.RData")
View(transitionMatrix)
?unlist
?states
suppressPackageStartupMessages(library(tm));suppressPackageStartupMessages(library(RWeka));
suppressPackageStartupMessages(library(stringi));suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidyr));suppressPackageStartupMessages(library(R.utils))
suppressPackageStartupMessages(library(plyr));suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(markovchain))
?states
runif(1)
?paste0
commonIdx = numeric()
load("/Users/malaydas/Downloads/transitionMatrix (2).RData")
View(transitionMatrix)
?rbinom
?rbinom()
OutputData="/Users/malaydas/Documents/Data Science/Capstone Project/data/OutputData/"
TransitionMatrixPath = file.path(OutputData,"Initial_Trigram_TransitionMatrix.RData")
load(TransitionMatrixPath)
sum(transitionMatrix[1,0])
sum(transitionMatrix[1,])
sum(transitionMatrix[2,])
sum(transitionMatrix[5,])
sum(transitionMatrix[100,])
sum(transitionMatrix[900],])
sum(transitionMatrix[900,])
View(transitionMatrix)
load(file=file.path(OutputData,"Unigram.RData"))
tail(Unigram)
Unigram[which(Unigram$count)==60]
Unigram[which(Unigram$count==60)]
Unigram[which(Unigram$count==60),]
?subset
Unigram=subset(Unigram,count>49)
tail(Unigram)
load(file.path(OutputData,"Unigram.RData"))
Unigram=subset(Unigram,count>9)
tail(Unigram)
load(file.path(OutputData,"Unigram.RData"))
Unigram=subset(Unigram,count>19)
tail(Unigram)
load(file.path(OutputData,"Unigram.RData"))
Unigram=subset(Unigram,count>29)
tail(Unigram)
load(file.path(OutputData,"Trigram.RData"))
tail(Trigram)
head(Trigram)
grep("'",Trigram$word)
grep("for the",Trigram$word)
head(grep("for the",Trigram$word))
Trigram[head(grep("for the",Trigram$word)),]
tail(subset(Trigram,Trigram$count>5))
CurWords = unlist(str_split(names(MatchTrigram[1])," "))
?str_split
str_split(Trigram$words[1])
library(stringr)
str_split(Trigram$words[1])
library(stringi)
str_split(Trigram$words[1])
x<- "I can't do this anymore.They should've been carefull"
gsub("[[:punct:]]"," ",tolower(x))
curPhrase<- "I am not well"
curPhrase[1]
library(MarkovChain)
library(markovchain)
?conditionalDistribution
InputPhrase =    unlist(str_split(as.character(CurPhrase)," "))
InputPhrase =    unlist(str_split(as.character(curPhrase)," "))
library(stringi)
InputPhrase =    unlist(str_split(as.character(curPhrase)," "))
library(stringr)
InputPhrase =    unlist(str_split(as.character(curPhrase)," "))
InputPhrase
length(InputPhrase)
class(InputPhrase)
class(curPhrase)
Setting up the processing directory
ProgramDir="/Users/malaydas/Documents/Data Science/Capstone Project/ProgramingAssignment/Capstone/";setwd(ProgramDir)
InputData="/Users/malaydas/Documents/Data Science/Capstone Project/data/InputData/en_US/"
OutputData="/Users/malaydas/Documents/Data Science/Capstone Project/data/OutputData/"
SampleData="/Users/malaydas/Documents/Data Science/Capstone Project/data/SampleData/"
TrainingData="/Users/malaydas/Documents/Data Science/Capstone Project/data/TrainingData/"
TestData="/Users/malaydas/Documents/Data Science/Capstone Project/data/TestData/"
ValidationData="/Users/malaydas/Documents/Data Science/Capstone Project/data/ValidationData/"
list.files()
my.file.rename(from = file.path(OutputData,"MarkovObjects.RData"),
to = file.path(ProgramDir,"MarkovObjects.RData"))
capstone.file.copy <- function(from, to) {
todir <- dirname(to)
if (!isTRUE(file.info(todir)$isdir)) dir.create(todir, recursive=TRUE)
file.copy(from = from,  to = to)
}
my.file.rename(from = file.path(OutputData,"MarkovObjects.RData"),
to = file.path(ProgramDir,"MarkovObjects.RData"))
## Copy the Markov chain objects to a shiny application directory
capstone.file.copy(from = file.path(OutputData,"MarkovObjects.RData"),
to = file.path(ProgramDir,"MarkovObjects.RData"))
library(shiny)
?renderText
capstone.file.copy(from = file.path(OutputData,"Quadrigram.RData"),
to = file.path(ProgramDir,"Quadrigram.RData"))
capstone.file.copy(from = file.path(OutputData,"Trigram.RData"),
to = file.path(ProgramDir,"Trigram.RData"))
capstone.file.copy(from = file.path(OutputData,"Bigram.RData"),
to = file.path(ProgramDir,"Bigram.RData"))
getwd()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp(displayMode='showcase')
runApp(displayMode='Showcase')
runApp(display.mode='showcase')
runApp(display.mode='showcase')
install.packages("shinyIncubator")
runApp(display.mode='showcase')
runApp(display.mode='showcase')
setwd("Users/malaydas/Documents/Data Science/Developing Data Products/Programing Assignment/Data_Product_Assignment1")
setwd("Users/malaydas/Documents/Data Science/Developing Data Products/Programing Assignment/Data_Product_Assignment1/")
setwd("/Users/malaydas/Documents/Data Science/Developing Data Products/Programing Assignment/Data_Product_Assignment1/")
runApp(display.mode='showcase')
ProgramDir="/Users/malaydas/Documents/Data Science/Capstone Project/ProgramingAssignment/Capstone/";setwd(ProgramDir)
runApp(display.mode='showcase')
runApp(display.mode='showcase')
load(file="./MarkovObjects.RData")
load(file="./Quadrigram.RData")
load(file="./Trigram.RData")
load(file="./Bigram.RData"
)
NextWord("Welcome to the ",MarkovMatrix,Quadrigram,Trigram,Bigram)
source("./Capstone_Utilities.R")
NextWord("Welcome to the ",MarkovMatrix,Quadrigram,Trigram,Bigram)
source("./Capstone_Utilities.R")
NextWord("Welcome to the ",MarkovMatrix,Quadrigram,Trigram,Bigram)
source("./Capstone_Utilities.R")
NextWord("Welcome to the ",MarkovMatrix,Quadrigram,Trigram,Bigram)
ToMatch = unlist(str_split(as.character(InputPhrase)," "))
InputPhrase="welcome to the"
ToMatch = unlist(str_split(as.character(InputPhrase)," "))
ToMatch
WordPredictedS = PredictNextWordUsingStupidBackoff(ToMatch,Quadrigram,Trigram,Bigram)
WordPredictedS
WordPredictedM = PredictNextWordUsingMarkov(ToMatch,MarkovMatrix)
WordPredictedM
PossibleNextWordsCP =head(t(as.matrix(WordPredictedM$PossibleWordConditionalProbability)),2)
PossibleNextWordsCP
max(PossibleNextWordsM$PossibleWordConditionalProbability)
max(WordPredictedM$PossibleWordConditionalProbability)
names(max(WordPredictedM$PossibleWordConditionalProbability))
names(max(t(WordPredictedM$PossibleWordConditionalProbability))
)
grep("0.05421628",WordPredictedM$PossibleWordConditionalProbability)
x<-data.frame(word=colnames(WordPredictedM$PossibleWordConditionalProbability),prob=WordPredictedM$PossibleWordConditionalProbability)
x<-data.frame(word=rownames(WordPredictedM$PossibleWordConditionalProbability),prob=WordPredictedM$PossibleWordConditionalProbability)
x<-data.frame(word=rownames(WordPredictedM$PossibleWordConditionalProbability),prob=as.numeric(WordPredictedM$PossibleWordConditionalProbability))
WordPredictedM = PredictNextWordUsingMarkov(ToMatch,MarkovMatrix)
PossibleNextWordsCP =t(as.matrix(WordPredictedM$PossibleWordConditionalProbability))
PossibleNextWords = as.vector(colnames(PossibleNextWordsCP)[1:5])
PossibleNextWords
WordPredictedS
WordPredictedM$ExactWordPredicted
NextWord(InputPhrase,MarkovMatrix,Quadrigram,Trigram,Bigram)
source("./Capstone_Utilities.R")
NextWord(InputPhrase,MarkovMatrix,Quadrigram,Trigram,Bigram)
source("./Capstone_Utilities.R")
NextWord(InputPhrase,MarkovMatrix,Quadrigram,Trigram,Bigram)
runApp()
runApp()
runApp()
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
runApp(display.mode="showcase")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
x=list( y=c(1,2,3,4),z=c("a","b"))
x$y
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp(display.mode="showcase")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp(display.mode="showcase")
load(file="./MarkovObjects.RData")
shiny::runApp(display.mode="showcase")
shiny::runApp()
shiny::runApp(display.mode="showcase")
tolower("My nam Is Malay")
shiny::runApp()
shiny::runApp(display.mode="showcase")
shiny::runApp()
shiny::runApp(display.mode="showcase")
shiny::runApp()
shiny::runApp()
View(Quadrigram)
View(Quadrigram)
View(TransitionMatrix)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
